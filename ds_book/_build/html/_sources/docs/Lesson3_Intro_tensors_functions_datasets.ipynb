{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# Introduction to Tensors, TensorFlow Functions and TensorFlow Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial, we will learn about some key aspects of TensorFlow. We will start by discussing tensors, then we will talk about `tf.function`s and when to use them. Lastly we will discuss `tf.data.Dataset` methods and how to create tensor-formatted datasets."
      ],
      "metadata": {
        "id": "pVaq-F6yw97K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AL2hzxorJiWy"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRK5-9EpYbzG"
      },
      "source": [
        "## Basics of tensors\n",
        "\n",
        "Let's create some basic tensors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ3s2J8Vgowq"
      },
      "source": [
        "A tensor is a multi-dimensional array with a consistent type (known as a `dtype`).  All supported `dtypes` cna be seen with `tf.dtypes.DType`.\n",
        "\n",
        "Tensors are similar to [NumPy](https://numpy.org/devdocs/user/quickstart.html)  `np.arrays`.\n",
        "\n",
        "Tensors are immutable, just like Python numbers and strings. The contents of a tensor can never be updated; only new ones can be created.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSHRFT6LJbxq"
      },
      "source": [
        "A \"scalar\" is a \"rank-0\" tensor. It contains a single value and no \"axes\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5JcgLFR6gHv"
      },
      "outputs": [],
      "source": [
        "# This will be an int32 tensor by default; see \"dtypes\" below.\n",
        "rank_0_tensor = tf.constant(4)\n",
        "print(rank_0_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdmPAn9fWYs5"
      },
      "source": [
        "A \"vector\" is a \"rank-1\" tensor and contains something like a list of values. A vector is characterized by having one axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZos8o_R6oE7"
      },
      "outputs": [],
      "source": [
        "# Let's make this a float tensor.\n",
        "rank_1_tensor = tf.constant([2.0, 3.0, 4.0])\n",
        "print(rank_1_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3IJG-ug_H4u"
      },
      "source": [
        "A \"matrix\" is a \"rank-2\" tensor and it has two axes. This is what a single channel image turns out to be in tensor format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnOIA_xb6u0M"
      },
      "outputs": [],
      "source": [
        "# If you want to be specific, you can set the dtype (see below) at creation time\n",
        "rank_2_tensor = tf.constant([[1, 2],\n",
        "                             [3, 4],\n",
        "                             [5, 6]], dtype=tf.float16)\n",
        "print(rank_2_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19m72qEPkfxi"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th>A scalar, shape: <code>[]</code></th>\n",
        "  <th>A vector, shape: <code>[3]</code></th>\n",
        "  <th>A matrix, shape: <code>[3, 2]</code></th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/scalar.png?raw=1\" alt=\"A scalar, the number 4\" />\n",
        "  </td>\n",
        "\n",
        "  <td>\n",
        "   <img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/vector.png?raw=1\" alt=\"The line with 3 sections, each one containing a number.\"/>\n",
        "  </td>\n",
        "  <td>\n",
        "   <img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/matrix.png?raw=1\" alt=\"A 3x2 grid, with each cell containing a number.\">\n",
        "  </td>\n",
        "</tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjFvzcn4_ehD"
      },
      "source": [
        "Tensors can feature more axes, as is required for representation of multi-channel images. For example, we can have a tensor with three axes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sesW7gw6JkXy"
      },
      "outputs": [],
      "source": [
        "# There can be an arbitrary number of\n",
        "# axes (sometimes called \"dimensions\")\n",
        "rank_3_tensor = tf.constant([\n",
        "  [[0, 1, 2, 3, 4],\n",
        "   [5, 6, 7, 8, 9]],\n",
        "  [[10, 11, 12, 13, 14],\n",
        "   [15, 16, 17, 18, 19]],\n",
        "  [[20, 21, 22, 23, 24],\n",
        "   [25, 26, 27, 28, 29]],])\n",
        "\n",
        "print(rank_3_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM2sTGIkoE3S"
      },
      "source": [
        "A tensor with more than two axes can be visualized in several ways."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFiYfNMMhDgL"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th colspan=3>A 3-axis tensor, shape: <code>[3, 2, 5]</code></th>\n",
        "<tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/3-axis_numpy.png?raw=1\"/>\n",
        "  </td>\n",
        "  <td>\n",
        "   <img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/3-axis_front.png?raw=1\"/>\n",
        "  </td>\n",
        "\n",
        "  <td>\n",
        "   <img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/3-axis_block.png?raw=1\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWAc0U8OZwNb"
      },
      "source": [
        "NumPy arrays can be created from tensors using either the `np.array` or `tensor.numpy` methods:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5u6_6ZYaS7B"
      },
      "outputs": [],
      "source": [
        "np.array(rank_2_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6Taz2gIaZeo"
      },
      "outputs": [],
      "source": [
        "rank_2_tensor.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnz19F0ocEKD"
      },
      "source": [
        "Most tensors we encounter in computer vision contain floats and integers, but tensors can also represent other types, such as:\n",
        "\n",
        "* complex numbers\n",
        "* strings\n",
        "\n",
        "TensorFlow requires a `tf.Tensor` to be \"rectangular,\" which means that every element along an axis is the same size. There are exceptions to this (ragged and sparse tensors, but those are more rare and mostly out of scope for now)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDC7OGeAIJr8"
      },
      "source": [
        "We can calculate basic mathematical operations on tensors, such as addition, element-wise multiplication, and matrix multiplication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DTkjwDOIIDa"
      },
      "outputs": [],
      "source": [
        "a = tf.constant([[1, 2],\n",
        "                 [3, 4]])\n",
        "b = tf.constant([[1, 1],\n",
        "                 [1, 1]]) # Could have also said `tf.ones([2,2], dtype=tf.int32)`\n",
        "\n",
        "print(tf.add(a, b), \"\\n\") # element-wise addition\n",
        "print(tf.multiply(a, b), \"\\n\") # element-wise multiplication\n",
        "print(tf.matmul(a, b), \"\\n\") # matrix multiplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2smoWeUz-N2q"
      },
      "outputs": [],
      "source": [
        "print(a + b, \"\\n\") # element-wise addition\n",
        "print(a * b, \"\\n\") # element-wise multiplication\n",
        "print(a @ b, \"\\n\") # matrix multiplication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3_vIAl2JPVc"
      },
      "source": [
        "Tensors are used in many types of operations (or \"Ops\"), such as common machine learning operations like `tf.math.argmax` and `tf.nn.softmax`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gp4WUYzGIbnv"
      },
      "outputs": [],
      "source": [
        "c = tf.constant([[4.0, 5.0], [10.0, 1.0]])\n",
        "\n",
        "# Find the largest value\n",
        "print(tf.reduce_max(c))\n",
        "# Find the index of the largest value\n",
        "print(tf.math.argmax(c))\n",
        "# Compute the softmax\n",
        "print(tf.nn.softmax(c))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MNM-q7-MZLz"
      },
      "source": [
        "Generally, where tensors are expected, TensorFlow functions additionally accept anything that can be converted to a `Tensor` using `tf.convert_to_tensor`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wch0N8xNEt-"
      },
      "outputs": [],
      "source": [
        "tf.convert_to_tensor([1,2,3]) # List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngqIeWYeNJVI"
      },
      "outputs": [],
      "source": [
        "tf.reduce_max([1,2,3]) # List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThVMxqbVNOq3"
      },
      "outputs": [],
      "source": [
        "tf.reduce_max(np.array([1,2,3])) # NumPy array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvSAbowVVuRr"
      },
      "source": [
        "## Significance of Tensor shapes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkaBIqkTCcGY"
      },
      "source": [
        "A tensor has a shape.  Some key terms to know:\n",
        "\n",
        "* **Shape**: Describes the number of axes and length (number of elements) in each axis of a tensor.\n",
        "* **Rank**: Determined by the number of axes in a tensor.  If you recall, scalars are rank 0, vectors rank 1, matrices rank 2.\n",
        "* **Axis** or **Dimension**: A dimension of a tensor.\n",
        "* **Size**: The total number of elements in a tensor. This can be expressed as the product of the shape vector's elements, e.g. a tensor shape of (256, 256, 3) will have a size of 196608.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFOyG2tn8LhW"
      },
      "source": [
        "`tf.TensorShape` objects describe these key properties and more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RyD3yewUKdnK"
      },
      "outputs": [],
      "source": [
        "rank_4_tensor = tf.zeros([3, 2, 4, 5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTZZW9ziq4og"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th colspan=2>A rank-4 tensor, shape: <code>[3, 2, 4, 5]</code></th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/shape.png?raw=1\" alt=\"A tensor shape is like a vector.\">\n",
        "    <td>\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/4-axis_block.png?raw=1\" alt=\"A 4-axis tensor\">\n",
        "  </td>\n",
        "  </tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHm9vSqogsBk"
      },
      "outputs": [],
      "source": [
        "print(\"Type of every element:\", rank_4_tensor.dtype)\n",
        "print(\"Number of axes:\", rank_4_tensor.ndim)\n",
        "print(\"Rank: \", tf.rank(rank_4_tensor))\n",
        "print(\"Shape of tensor:\", rank_4_tensor.shape)\n",
        "print(\"Elements along axis 0 of tensor:\", rank_4_tensor.shape[0])\n",
        "print(\"Elements along the last axis of tensor:\", rank_4_tensor.shape[-1])\n",
        "print(\"Total number of elements (3*2*4*5): \", tf.size(rank_4_tensor).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQmE_Vx5JilS"
      },
      "source": [
        "Axes of a tensor follow a global to local ordering. For example, in machine learning we often talk about batches. For a given batch, the dimension of the batch is ordered first, followed by the batch element's spatial dimensions (height, width) and then the channels (referred to as features in the below diagram).\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "<th>Typical axis order</th>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/shape2.png?raw=1\" alt=\"Keep track of what each axis is. A 4-axis tensor might be: Batch, Width, Height, Channels\">\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlPoVvJS75Bb"
      },
      "source": [
        "## Indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apOkCKqCZIZu"
      },
      "source": [
        "### Single-axis indexing\n",
        "\n",
        "In TensorFlow, standard Python indexing rules apply. Indexing tensors looks similar to [indexing a list in Python](https://docs.python.org/3/tutorial/introduction.html#strings). The same applied for NumPy-style indexing.\n",
        "\n",
        "* indexes begin at `0`\n",
        "* negative indices count backwards from the end\n",
        "* colons, `:`, are used for slices: `start:stop:step`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQ-CrJxLXTIM"
      },
      "outputs": [],
      "source": [
        "rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])\n",
        "print(rank_1_tensor.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When using a scalar to get an element in the tensor, the axis is removed."
      ],
      "metadata": {
        "id": "2cBo-BJeUSLy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6tqHciOWMt5"
      },
      "outputs": [],
      "source": [
        "print(\"First:\", rank_1_tensor[0].numpy())\n",
        "print(\"Second:\", rank_1_tensor[1].numpy())\n",
        "print(\"Last:\", rank_1_tensor[-1].numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJLHU_a2XwpG"
      },
      "source": [
        "When a slice is indexed using `:` the axis is retained:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giVPPcfQX-cu"
      },
      "outputs": [],
      "source": [
        "print(\"Everything:\", rank_1_tensor[:].numpy())\n",
        "print(\"Before 4:\", rank_1_tensor[:4].numpy())\n",
        "print(\"From 4 to the end:\", rank_1_tensor[4:].numpy())\n",
        "print(\"From 2, before 7:\", rank_1_tensor[2:7].numpy())\n",
        "print(\"Every other item:\", rank_1_tensor[::2].numpy())\n",
        "print(\"Reversed:\", rank_1_tensor[::-1].numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elDSxXi7X-Bh"
      },
      "source": [
        "### Multi-axis indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cgk0uRUYZiai"
      },
      "source": [
        "When working with higher ranks of tensors, we may have to use multiple indices.\n",
        "\n",
        "To do this, we treat each axis independently with the exact same rules as in the single-axis case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tc5X_WlsZXmd"
      },
      "outputs": [],
      "source": [
        "print(rank_2_tensor.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w07U9vq5ipQk"
      },
      "source": [
        "If we pass an integer for each index for each axis, a scalar is returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvILXc1PjqTM"
      },
      "outputs": [],
      "source": [
        "# Pull out a single value from a 2-rank tensor\n",
        "print(rank_2_tensor[1, 1].numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RLCzAOHjfEH"
      },
      "source": [
        "We can combine integers and slices when indexing too. This can be useful if, for example, we want a subset of an image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTqNqsfJkJP_"
      },
      "outputs": [],
      "source": [
        "# Get row and column tensors\n",
        "print(\"Second row:\", rank_2_tensor[1, :].numpy())\n",
        "print(\"Second column:\", rank_2_tensor[:, 1].numpy())\n",
        "print(\"Last row:\", rank_2_tensor[-1, :].numpy())\n",
        "print(\"First item in last column:\", rank_2_tensor[0, -1].numpy())\n",
        "print(\"Skip the first row:\")\n",
        "print(rank_2_tensor[1:, :].numpy(), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P45TwSUVSK6G"
      },
      "source": [
        "An example for a tensor with 3 axes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuLoMoCVSLxK"
      },
      "outputs": [],
      "source": [
        "print(rank_3_tensor[:, :, 4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NgmHq27TJOE"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "<th colspan=2>Selecting the last feature across all locations in each example in the batch </th>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/index1.png?raw=1\" alt=\"A 3x2x5 tensor with all the values at the index-4 of the last axis selected.\">\n",
        "  </td>\n",
        "      <td>\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/index2.png?raw=1\" alt=\"The selected values packed into a 2-axis tensor.\">\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9V83-thHn89"
      },
      "source": [
        "More on how to apply indexing can be found in the [tensor slicing guide](https://tensorflow.org/guide/tensor_slicing)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpr7R0t4SVb0"
      },
      "source": [
        "## Manipulating tensor shapes\n",
        "\n",
        "Sometimes, we need to reshape a tensor. For example, we flatten rank 2 tensors to rank 1 when computing things like confusion matrices.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape returns a `TensorShape` object that shows the size along each axis\n",
        "x = tf.constant([[1, 2, 3],\n",
        "                [4, 5, 6],\n",
        "                [7, 8, 9]])\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "-SY3pTQ8bLyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the rank 2 tensor to rank 1 (a vector)\n",
        "x_flat = tf.reshape(x, [-1])\n",
        "print(x_flat)"
      ],
      "metadata": {
        "id": "ZL-qTKj3bZ-z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMeTtga5Wq8j"
      },
      "outputs": [],
      "source": [
        "# Shape returns a `TensorShape` object that shows the size along each axis\n",
        "x = tf.constant([[1], [2], [3]])\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38jc2RXziT3W"
      },
      "outputs": [],
      "source": [
        "# You can convert this object into a Python list, too\n",
        "print(x.shape.as_list())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_xRlHZMKYnF"
      },
      "source": [
        "A tensor can be manipulated into a new shape using the `tf.reshape` operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pa9JCgMLWy87"
      },
      "outputs": [],
      "source": [
        "# You can reshape a tensor to a new shape.\n",
        "# Note that you're passing in a list\n",
        "reshaped = tf.reshape(x, [1, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mcq7iXOkW3LK"
      },
      "outputs": [],
      "source": [
        "print(x.shape)\n",
        "print(reshaped.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIB2tOkoVr6E"
      },
      "source": [
        "The original tensor and the newly created one are both held in memory (remember tensors are immutable). TensorFlow abides by C-style \"row-major\" memory ordering, which means that an increment on the rightmost index corresponds to a single step in memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kMfM0RpUgI8"
      },
      "outputs": [],
      "source": [
        "print(rank_3_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcDtfQkJWzIx"
      },
      "source": [
        "In fact, flattening a tensor shows the order in which it is held in memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COnHEPuaWDQp"
      },
      "outputs": [],
      "source": [
        "# A `-1` passed in the `shape` argument says \"Whatever fits\".\n",
        "print(tf.reshape(rank_3_tensor, [-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJZRira2W--c"
      },
      "source": [
        "Generally we use `tf.reshape` to combine or split adjacent axes (or add/remove `1`s, similar to `np.squeeze`).\n",
        "\n",
        "Taking the below 3x2x5 tensor, we can reshape to (3x2)x5 or 3x(2x5) for example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zP2Iqc7zWu_J"
      },
      "outputs": [],
      "source": [
        "print(tf.reshape(rank_3_tensor, [3*2, 5]), \"\\n\")\n",
        "print(tf.reshape(rank_3_tensor, [3, -1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZsZRUhihlDB"
      },
      "source": [
        "<table>\n",
        "<th colspan=3>\n",
        "Some good reshapes.\n",
        "</th>\n",
        "<tr>\n",
        "  <td>\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/reshape-before.png?raw=1\" alt=\"A 3x2x5 tensor\">\n",
        "  </td>\n",
        "  <td>\n",
        "  <img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/reshape-good1.png?raw=1\" alt=\"The same data reshaped to (3x2)x5\">\n",
        "  </td>\n",
        "  <td>\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/reshape-good2.png?raw=1\" alt=\"The same data reshaped to 3x(2x5)\">\n",
        "  </td>\n",
        "</tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOcRxDC3jNIU"
      },
      "source": [
        "Notes:\n",
        "*   We can reshape a tensor to a new shape so long as it entails the same total number of elements (size).\n",
        "*   Shifting the order of axes is done with `tf.transpose` instead of `tf.reshape`.\n",
        "*   You may run across not-fully-specified shapes. Either the shape contains a `None` (an axis-length is unknown) or the whole shape is `None` (the rank of the tensor is unknown). This is often useful for machine learning when the images in a batch may have non-uniform width and height dimensions.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDmFtFM7k0R2"
      },
      "source": [
        "## Tensor `DTypes`\n",
        "\n",
        "We can find a `tf.Tensor`'s data type by inspecting the `Tensor.dtype` property.\n",
        "\n",
        "Datatypes can be optionally specified when creating a `tf.Tensor` from a Python object. If left unspecified, TensorFlow inuits and assigns a datatype that can reasonably represent the data. By default, TensorFlow translates Python integers as `tf.int32` and Python floating point numbers as `tf.float32`.\n",
        "\n",
        "Tensors can be cast to other types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mSTDWbelUvu"
      },
      "outputs": [],
      "source": [
        "the_f64_tensor = tf.constant([2.2, 3.3, 4.4], dtype=tf.float64)\n",
        "the_f16_tensor = tf.cast(the_f64_tensor, dtype=tf.float16)\n",
        "# Now, cast to an uint8 and lose the decimal precision\n",
        "the_u8_tensor = tf.cast(the_f16_tensor, dtype=tf.uint8)\n",
        "print(the_u8_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1yBlJsVlFSu"
      },
      "source": [
        "## Broadcasting\n",
        "\n",
        "Broadcasting in TensorFlow is based on the [equivalent method in NumPy](https://numpy.org/doc/stable/user/basics.broadcasting.html).  The premise is that sometimes we need to stretch smaller tensors automatically to fit the size of larger tensors to run combined operations on them.\n",
        "\n",
        "A simple example is multiplying or adding a tensor to a scalar. The scalar in this case is broadcast to the same shape as the tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8sypqmagHQN"
      },
      "outputs": [],
      "source": [
        "x = tf.constant([1, 2, 3])\n",
        "\n",
        "y = tf.constant(2)\n",
        "z = tf.constant([2, 2, 2])\n",
        "# All of these are the same computation\n",
        "print(tf.multiply(x, 2))\n",
        "print(x * y)\n",
        "print(x * z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0SBoR6voWcb"
      },
      "source": [
        "Furthermore, tensors with an axis of length 1 can be stretched to match the axis length of another tensor during a combined operation.  \n",
        "\n",
        "As an example, a 3x1 matrix can be element-wise multiplied by a 1x4 matrix to result in a 3x4 matrix. The notation of the axis with length 1 is optional. In other words, the real shape of y is `[4]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sGmkPg3XANr"
      },
      "outputs": [],
      "source": [
        "# These are the same computations\n",
        "x = tf.reshape(x,[3,1])\n",
        "y = tf.range(1, 5)\n",
        "print(x, \"\\n\")\n",
        "print(y, \"\\n\")\n",
        "print(tf.multiply(x, y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_7sh-EUYLrE"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th>A broadcasted add: a <code>[3, 1]</code> times a <code>[1, 4]</code> gives a <code>[3,4]</code> </th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/broadcasting.png?raw=1\" alt=\"Adding a 3x1 matrix to a 4x1 matrix results in a 3x4 matrix\">\n",
        "  </td>\n",
        "</tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V3KgSJcKDRz"
      },
      "source": [
        "The same operation without broadcasting looks like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elrF6v63igY8"
      },
      "outputs": [],
      "source": [
        "x_stretch = tf.constant([[1, 1, 1, 1],\n",
        "                         [2, 2, 2, 2],\n",
        "                         [3, 3, 3, 3]])\n",
        "\n",
        "y_stretch = tf.constant([[1, 2, 3, 4],\n",
        "                         [1, 2, 3, 4],\n",
        "                         [1, 2, 3, 4]])\n",
        "\n",
        "print(x_stretch * y_stretch)  # Again, operator overloading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14KobqYu85gi"
      },
      "source": [
        "Broadcasting is usually both time and space efficient, as it never creates the expanded tensors in memory.  \n",
        "\n",
        "The broadcasting operation can be observed with `tf.broadcast_to`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GW2Q59_r8hZ6"
      },
      "outputs": [],
      "source": [
        "print(tf.broadcast_to(tf.constant([1, 2, 3]), [3, 3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2bAMMQY-jpP"
      },
      "source": [
        "More on broadcasting can be found in [this section](https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html) of Jake VanderPlas's book _Python Data Science Handbook_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4Rpz0xAsKSI"
      },
      "source": [
        "## tf.convert_to_tensor\n",
        "\n",
        "As a reminder, most TensorFlow operations that expect arguments of class `tf.Tensor`, such as `tf.matmul` and `tf.reshape`, will also accept Python objects shaped like tensors.\n",
        "\n",
        "Under the hood, most TensorFlow ops apply `convert_to_tensor` to non-tensor arguments, such as NumPy's `ndarray`, `TensorShape`, Python lists, and `tf.Variable`, all of which will convert automatically.\n",
        "\n",
        "See the conversion registry `tf.register_tensor_conversion_function` to know whether a data type will automatically convert."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9njclVkkN7G"
      },
      "source": [
        "## String tensors\n",
        "\n",
        "`tf.string` is a `dtype` that represents data as strings (variable-length byte arrays) in tensors.\n",
        "\n",
        "However, string tensors are atomic meaning that they cannot be indexed the way Python strings can. See `tf.strings` for ways to manipulate them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P_8spEGQ0wp"
      },
      "source": [
        "An example of a scalar string tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBosmM8MkIh4"
      },
      "outputs": [],
      "source": [
        "# Tensors can be strings, too here is a scalar string.\n",
        "scalar_string_tensor = tf.constant(\"Lima Peru\")\n",
        "print(scalar_string_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41Dv2kL9QrtO"
      },
      "outputs": [],
      "source": [
        "# If you have three string tensors of different lengths, this is OK.\n",
        "tensor_of_strings = tf.constant([\"Lima Peru\",\n",
        "                                 \"NASA SERVIR\",\n",
        "                                 \"Development Seed\"])\n",
        "# Note that the shape is (3,). The string length is not included.\n",
        "print(tensor_of_strings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76gQ9qrgSMzS"
      },
      "source": [
        "The `b` prefix in the above printout indicates that the `tf.string` dtype is a byte-string, not a unicode string. For more on how to use unicode text in TensorFlow see the [Unicode Tutorial](https://www.tensorflow.org/tutorials/load_data/unicode)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClSBPK-lZBQp"
      },
      "source": [
        "Also worth noting, unicode characters in TensorFlow are utf-8 encoded."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir9cY42MMAei"
      },
      "source": [
        "`tf.strings` contains some basic string operations, including `tf.strings.split`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8k2K0VTFyj8e"
      },
      "outputs": [],
      "source": [
        "# You can use split to split a string into a set of tensors\n",
        "print(tf.strings.split(scalar_string_tensor, sep=\" \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgGAn1dfR-04"
      },
      "outputs": [],
      "source": [
        "# ...but it turns into a what is known as a `RaggedTensor` if you split up a tensor of strings,\n",
        "# as each string might be split into a different number of parts.\n",
        "print(tf.strings.split(tensor_of_strings))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st9OxrUxWSKY"
      },
      "source": [
        "And we also have `tf.string.to_number`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nRtx3X9WRfN"
      },
      "outputs": [],
      "source": [
        "text = tf.constant(\"1 10 100\")\n",
        "print(tf.strings.to_number(tf.strings.split(text, \" \")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE7nKJ2YW3aY"
      },
      "source": [
        "In TensorFlow, the `tf.string` dtype describes all raw bytes data. The `tf.io` module is used to convert data to and from bytes, as is done when decoding images and parsing text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ua8BnAzxkRKV"
      },
      "source": [
        "## Sparse tensors\n",
        "\n",
        "Data can sometimes be sparse, as might be the case for a wide embedding space.  TensorFlow has a datat type called `tf.sparse.SparseTensor` and related operations to support sparse data and work efficiently with it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS5zgqgUTPRb"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th>A `tf.SparseTensor`, shape: <code>[3, 4]</code></th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/sparse.png?raw=1\" alt=\"An 3x4 grid, with values in only two of the cells.\">\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9nbO1E2kSUN"
      },
      "outputs": [],
      "source": [
        "# Sparse tensors store values by index in a memory-efficient manner\n",
        "sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],\n",
        "                                       values=[1, 2],\n",
        "                                       dense_shape=[3, 4])\n",
        "print(sparse_tensor, \"\\n\")\n",
        "\n",
        "# You can convert sparse tensors to dense\n",
        "print(tf.sparse.to_dense(sparse_tensor))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions\n",
        "\n",
        "In TensorFlow 2, [eager execution](eager.ipynb) mode is on by default. This mode enables intuitive use, rapid experimentation and flexibility. However, this mode faces limits with performance and deployability.\n",
        "\n",
        "`tf.function` is used to make graphs out of programs. The critical case for it is when we need to build Python-independent dataflow graphs from Python code, with goal of creating performant and portable models. In fact, compiling in `tf.function` is required to use the `SavedModel` class.\n",
        "\n",
        "We will discuss some of the main uses for `tf.function`.\n",
        "\n",
        "Before that, it's worth knowing how and when `tf.function` is recommended:\n",
        "\n",
        "- Debugging is best done in eager mode, then functions from that should be decorated with `@tf.function`.\n",
        "- Use `tf.function` to avoid on Python side effects like object mutation or list appends."
      ],
      "metadata": {
        "id": "FD7Ur2bkHxn8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usage\n",
        "\n",
        "A `Function` in TensorFlow, (which can be created by adding the `@tf.function` decorator) behaves like a core TensorFlow operation. It can be executed eagerly."
      ],
      "metadata": {
        "id": "0GEkEScgH9Bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function  # The decorator converts `add` into a `Function`.\n",
        "def add(a, b):\n",
        "  return a + b\n",
        "\n",
        "add(tf.ones([2, 2]), tf.ones([2, 2]))  #  [[2., 2.], [2., 2.]]"
      ],
      "metadata": {
        "id": "rNy_cPdAH9pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Function`s can be used inside other `Function`s."
      ],
      "metadata": {
        "id": "l151qACaIENW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def dense_layer(x, w, b):\n",
        "  return add(tf.matmul(x, w), b)\n",
        "\n",
        "dense_layer(tf.ones([3, 2]), tf.ones([2, 2]), tf.ones([2]))"
      ],
      "metadata": {
        "id": "NUYHnGfgIACj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In some cases, `Function`s are faster than their eager code equivalent. This is especially so for graphs with lots of small ops. However, on the flip side graphs with few expensive ops (like convolutions) may not benefit from much speedup."
      ],
      "metadata": {
        "id": "xtJfg4hmIK3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "conv_layer = tf.keras.layers.Conv2D(100, 3)\n",
        "\n",
        "@tf.function\n",
        "def conv_fn(image):\n",
        "  return conv_layer(image)\n",
        "\n",
        "image = tf.zeros([1, 200, 200, 100])\n",
        "# Warm up\n",
        "conv_layer(image); conv_fn(image)\n",
        "print(\"Eager conv:\", timeit.timeit(lambda: conv_layer(image), number=10))\n",
        "print(\"Function conv:\", timeit.timeit(lambda: conv_fn(image), number=10))\n",
        "print(\"Note how there's not much difference in performance for convolutions\")"
      ],
      "metadata": {
        "id": "PIdZjMj-ILYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Use unknown dimensions for flexibility\n",
        "\n",
        "  TensorFlow matches tensorson the basis of their shape. We can use a `None` dimension as a wildcard to allow `Function`s to run on variably-sized input. Variably-sized input is frequent when dealing with sequences of different length, or images of different spatial dimensions (sizes) across batches."
      ],
      "metadata": {
        "id": "HyD8-Jr0IXH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.int32),))\n",
        "def g(x):\n",
        "  print('Tracing with', x)\n",
        "  return x\n",
        "\n",
        "# No retrace!\n",
        "print(g(tf.constant([1, 2, 3])))\n",
        "print(g(tf.constant([1, 2, 3, 4, 5])))"
      ],
      "metadata": {
        "id": "mHKNuNj6IXvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using iterators and generators\n",
        "\n",
        "TensorFlow has a `tf.data.Iterator` for iteration. The [`tf.data`](https://www.tensorflow.org/guide/data) API helps implement generator patterns. TensorFlow's iterators and generators help avoid Python side effects which can surface outside of eager mode."
      ],
      "metadata": {
        "id": "0m3v0vHZIptO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def buggy_consume_next(iterator):\n",
        "  tf.print(\"Value:\", next(iterator))\n",
        "\n",
        "iterator = iter([1, 2, 3])\n",
        "buggy_consume_next(iterator)\n",
        "# This reuses the first value from the iterator, rather than consuming the next value.\n",
        "buggy_consume_next(iterator)\n",
        "buggy_consume_next(iterator)\n"
      ],
      "metadata": {
        "id": "v6J3wre3Is_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def good_consume_next(iterator):\n",
        "  # This is ok, iterator is a tf.data.Iterator\n",
        "  tf.print(\"Value:\", next(iterator))\n",
        "\n",
        "ds = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
        "iterator = iter(ds)\n",
        "good_consume_next(iterator)\n",
        "good_consume_next(iterator)\n",
        "good_consume_next(iterator)"
      ],
      "metadata": {
        "id": "LSLnGbzyIw2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data\n",
        "\n",
        "The `tf.data.Dataset` [API](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) represents methods to create tensor-formatted datasets out of many different types of data. It's also used in the making of data pipelines.\n",
        "\n",
        "Usage of the API follows the below pattern:\n",
        "\n",
        "*   Create a dataset from your input data.\n",
        "*   Iterate over the dataset, applying any dataset transformations to the data.\n",
        "\n",
        "Note that iteration occurs through streaming, so it dones't matter if a full dataset can't fit into memory.\n",
        "\n",
        "The simplest example of creating a dataset is from a python list:"
      ],
      "metadata": {
        "id": "JQrtvU81ySYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
        "for element in dataset:\n",
        "  print(element)"
      ],
      "metadata": {
        "id": "rLqqLeIPywjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformations:\n",
        "With a dataset, you can use transformations to prepare the data. In machine learning, sometimes we want to augment our data with image flips and rotations for example. Those could be done in the pipeline too."
      ],
      "metadata": {
        "id": "yXhDZA5gzKHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
        "dataset = dataset.map(lambda x: x*2)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "id": "ymCUQjZezKzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Common Terms:\n",
        "\n",
        "\n",
        "*   **Element**: A single result from calling next() on a dataset iterator. Elements are sometimes nested structures containing multiple components.\n",
        "\n",
        "*   **Component**: The single part in a nested structure of an element.\n",
        "\n",
        "Supported types:\n",
        "\n",
        "As nested structures, elements can contain tuples, named tuples, and dictionaries. This is different behavior than that of Python lists. Instead, Python lists require conversion to tensors and then may be treated as components. Element components can express as any type represented in `tf.TypeSpec`, which includes `tf.Tensor`, `tf.data.Datase`t, `tf.sparse.SparseTensor`, and `tf.TensorArray`."
      ],
      "metadata": {
        "id": "Rqoxr6q5zUk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = 1 # Integer element\n",
        "b = 2.0 # Float element\n",
        "c = (1, 2) # Tuple element with 2 components\n",
        "d = {\"a\": (2, 2), \"b\": 3} # Dict element with 3 components\n",
        "Point = collections.namedtuple(\"Point\", [\"x\", \"y\"])\n",
        "e = Point(1, 2) # Named tuple\n",
        "f = tf.data.Dataset.range(10) # Dataset element"
      ],
      "metadata": {
        "id": "yMZQ62iEztLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This discussion on datasets is different than the [TensorFlow Datasets collection](https://www.tensorflow.org/datasets) which hosts prepared datasets for TensorFlow models and analysis. We will explore use of the TensorFlow Datasets collection and more on the `tf.data.Dataset` API iterators and generators (datat pipes) in a follow up lesson."
      ],
      "metadata": {
        "id": "XQKT5K5s8cxe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook was adapted from [Introduction to Tensors](https://www.tensorflow.org/guide/tensor), [TensorFlow Functions](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/function.ipynb#scrollTo=HQrG5_kOiKl_), and [tf.data.Dataset API](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)."
      ],
      "metadata": {
        "id": "n91CDdmo9Hug"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}