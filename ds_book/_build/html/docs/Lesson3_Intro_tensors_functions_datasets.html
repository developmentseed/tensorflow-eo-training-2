

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Introduction to Tensors, TensorFlow Functions and TensorFlow Datasets &#8212; Deep learning with TensorFlow</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'docs/Lesson3_Intro_tensors_functions_datasets';</script>
    <link rel="shortcut icon" href="../_static/ds.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="What are cloud providers? Why might I need them for ML and Earth observation data?" href="Lesson4b_Integrations_with_Google_Cloud_Platform.html" />
    <link rel="prev" title="TensorFlow 2 and Keras quickstart for geospatial computer vision" href="Lesson2b_Intro_to_TF2_Keras_TFDS_RadiantEarth.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/ds.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/ds.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Lesson1a_Intro_ML_NN_DL.html">Introduction to machine learning, neural networks and deep learning</a></li>

<li class="toctree-l1"><a class="reference internal" href="Lesson2a_Intro_to_Google_Colab.html">Introduction to Google Colab</a></li>


<li class="toctree-l1"><a class="reference internal" href="Lesson2b_Intro_TensorFlow_Keras.html">Introduction to TensorFlow 2 and Keras</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lesson2b_Intro_to_TF2_Keras_TFDS_RadiantEarth.html">TensorFlow 2 and Keras quickstart for geospatial computer vision</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Introduction to Tensors, TensorFlow Functions and TensorFlow Datasets</a></li>


<li class="toctree-l1"><a class="reference internal" href="Lesson4b_Integrations_with_Google_Cloud_Platform.html">What are cloud providers? Why might I need them for ML and Earth observation data?</a></li>




<li class="toctree-l1"><a class="reference internal" href="Lesson5a_prep_data_ML_segmentation.html">Process dataset for use with deep learning segmentation network</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lesson5b_deeplearning_crop_segmentation.html">Semantic segmentation with deep learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lesson6a_evaluation.html">Evaluating Semantic Segmentation Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lesson6b_dealing_with_limited_data.html">Dealing with limited data for semantic segmentation</a></li>

<li class="toctree-l1"><a class="reference internal" href="appendix.html">Appendix</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/developmentseed/tensorflow-eo-training/main?urlpath=tree/ds_book/docs/Lesson3_Intro_tensors_functions_datasets.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/developmentseed/tensorflow-eo-training/blob/main/ds_book/docs/Lesson3_Intro_tensors_functions_datasets.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/developmentseed/tensorflow-eo-training" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/developmentseed/tensorflow-eo-training/edit/main/ds_book/docs/Lesson3_Intro_tensors_functions_datasets.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/developmentseed/tensorflow-eo-training/issues/new?title=Issue%20on%20page%20%2Fdocs/Lesson3_Intro_tensors_functions_datasets.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/docs/Lesson3_Intro_tensors_functions_datasets.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Introduction to Tensors, TensorFlow Functions and TensorFlow Datasets</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Introduction to Tensors, TensorFlow Functions and TensorFlow Datasets</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basics-of-tensors">Basics of tensors</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#significance-of-tensor-shapes">Significance of Tensor shapes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpreting-tensor-shapes">Interpreting tensor shapes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-tensors-often-used">Types of tensors often used</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#variables">Variables</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#indexing">Indexing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#single-axis-indexing">Single-axis indexing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-axis-indexing">Multi-axis indexing</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#manipulating-tensor-shapes">Manipulating tensor shapes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tensor-dtypes">Tensor <code class="docutils literal notranslate"><span class="pre">DTypes</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#broadcasting">Broadcasting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tf-convert-to-tensor">tf.convert_to_tensor</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#string-tensors">String tensors</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sparse-tensors">Sparse tensors</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#functions">Functions</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#usage">Usage</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-unknown-dimensions-for-flexibility">Use unknown dimensions for flexibility</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-iterators-and-generators">Using iterators and generators</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#data">Data</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-pipelines">Data pipelines</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="introduction-to-tensors-tensorflow-functions-and-tensorflow-datasets">
<h1>Introduction to Tensors, TensorFlow Functions and TensorFlow Datasets<a class="headerlink" href="#introduction-to-tensors-tensorflow-functions-and-tensorflow-datasets" title="Permalink to this heading">#</a></h1>
<p>In this tutorial, we will learn about some key aspects of TensorFlow. We will start by discussing tensors, then we will talk about <code class="docutils literal notranslate"><span class="pre">tf.function</span></code>s and when to use them. Lastly we will discuss <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> methods and how to create tensor-formatted datasets.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import tensorflow as tf
import numpy as np
</pre></div>
</div>
</div>
</div>
<section id="basics-of-tensors">
<h2>Basics of tensors<a class="headerlink" href="#basics-of-tensors" title="Permalink to this heading">#</a></h2>
<p>Let’s create some basic tensors.</p>
<p>A tensor is a multi-dimensional array with a consistent type (known as a <code class="docutils literal notranslate"><span class="pre">dtype</span></code>).  All supported <code class="docutils literal notranslate"><span class="pre">dtypes</span></code> can be seen with <code class="docutils literal notranslate"><span class="pre">tf.dtypes.DType</span></code>.</p>
<p>Tensors are similar to <a class="reference external" href="https://numpy.org/devdocs/user/quickstart.html">NumPy</a>  <code class="docutils literal notranslate"><span class="pre">np.arrays</span></code>.</p>
<p>Tensors are immutable, just like Python numbers and strings. The contents of a tensor can never be updated; only new ones can be created.</p>
<p>Note that we will use <code class="docutils literal notranslate"><span class="pre">tf.constant</span></code> regularly, and sometimes you’ll see <code class="docutils literal notranslate"><span class="pre">tf.variable</span></code> for similarly looking assignments. The difference between the two in TensorFlow usage is that, the value assigned to a constant cannot be changed in the future; it is static and the initialization is with a value, not an operation. Whereas for variable, the initialization can be a value or an operation, both of which can change. In the context of machine learning, we would want to assign the loss value as a variable as it changes with each epoch, whereas we would want to assign fixed hyper-parameters like batch size as a constant. Training samples (images for example) are also converted to tensors as constants as they don’t change.</p>
<p>Can you guess where else in the machine learning life cycle we would want to use variables instead of constants and vice versa?</p>
<section id="significance-of-tensor-shapes">
<h3>Significance of Tensor shapes<a class="headerlink" href="#significance-of-tensor-shapes" title="Permalink to this heading">#</a></h3>
<p>A tensor has a shape.  Some key terms to know:</p>
<ul class="simple">
<li><p><strong>Shape</strong>: Describes the number of axes and length (number of elements) in each axis of a tensor.</p></li>
<li><p><strong>Rank</strong>: Determined by the number of axes in a tensor.</p></li>
<li><p><strong>Axis</strong> or <strong>Dimension</strong>: A dimension of a tensor.</p></li>
<li><p><strong>Size</strong>: The total number of elements in a tensor. This can be expressed as the product of the shape vector’s elements, e.g. a tensor shape of (256, 256, 3) will have a size of 196608.</p></li>
</ul>
<p>A “scalar” is a “rank-0” tensor. It contains a single value and no “axes”.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># This will be an int32 tensor by default; see &quot;dtypes&quot; below.
rank_0_tensor = tf.constant(4)
print(rank_0_tensor)
</pre></div>
</div>
</div>
</div>
<p>A “vector” is a “rank-1” tensor and contains something like a list of values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># Let&#39;s make this a float tensor.
rank_1_tensor = tf.constant([2.0, 3.0, 4.0])
print(rank_1_tensor)
</pre></div>
</div>
</div>
</div>
<p>A “matrix” is a “rank-2” tensor and it has at least two axes. This is what a single channel image turns out to be in tensor format.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># If you want to be specific, you can set the dtype (see below) at creation time
rank_2_tensor = tf.constant([[1, 2],
                             [3, 4],
                             [5, 6]], dtype=tf.float16)
print(rank_2_tensor)
</pre></div>
</div>
</div>
</div>
<table>
<tr>
  <th>A scalar, shape: <code>[]</code></th>
  <th>A vector, shape: <code>[3]</code></th>
  <th>A matrix, shape: <code>[3, 2]</code></th>
</tr>
<tr>
  <td>
   <img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/scalar.png?raw=1" alt="A scalar, the number 4" />
  </td>
  <td>
   <img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/vector.png?raw=1" alt="The line with 3 sections, each one containing a number."/>
  </td>
  <td>
   <img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/matrix.png?raw=1" alt="A 3x2 grid, with each cell containing a number.">
  </td>
</tr>
</table>
<p>Tensors can feature more axes, as is required for representation of multi-channel images. For example, we can have a tensor with three axes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># There can be an arbitrary number of
# axes (sometimes called &quot;dimensions&quot;)
rank_3_tensor = tf.constant([
  [[0, 1, 2, 3, 4],
   [5, 6, 7, 8, 9]],
  [[10, 11, 12, 13, 14],
   [15, 16, 17, 18, 19]],
  [[20, 21, 22, 23, 24],
   [25, 26, 27, 28, 29]],])

print(rank_3_tensor)
</pre></div>
</div>
</div>
</div>
<p>A tensor with more than two axes can be visualized in several ways.</p>
<table>
<tr>
  <th colspan=3>A 3-axis tensor, shape: <code>[3, 2, 5]</code></th>
<tr>
<tr>
  <td>
   <img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/3-axis_numpy.png?raw=1"/>
  </td>
  <td>
   <img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/3-axis_front.png?raw=1"/>
  </td>
  <td>
   <img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/3-axis_block.png?raw=1"/>
  </td>
</tr>
</table></section>
<section id="interpreting-tensor-shapes">
<h3>Interpreting tensor shapes<a class="headerlink" href="#interpreting-tensor-shapes" title="Permalink to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">tf.TensorShape</span></code> objects describe some key properties of tensor shapes which help us understand the dimensionality of the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>rank_4_tensor = tf.zeros([3, 2, 4, 5]) # A fairly complex shape as an example
</pre></div>
</div>
</div>
</div>
<table>
<tr>
  <th colspan=2>A rank-4 tensor, shape: <code>[3, 2, 4, 5]</code></th>
</tr>
<tr>
  <td>
<img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/shape.png?raw=1" alt="A tensor shape is like a vector.">
    <td>
<img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/4-axis_block.png?raw=1" alt="A 4-axis tensor">
  </td>
  </tr>
</table>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>print(&quot;Type of every element:&quot;, rank_4_tensor.dtype)
print(&quot;Number of axes:&quot;, rank_4_tensor.ndim)
print(&quot;Rank: &quot;, tf.rank(rank_4_tensor))
print(&quot;Shape of tensor:&quot;, rank_4_tensor.shape)
print(&quot;Elements along axis 0 of tensor:&quot;, rank_4_tensor.shape[0])
print(&quot;Elements along the last axis of tensor:&quot;, rank_4_tensor.shape[-1])
print(&quot;Total number of elements (3*2*4*5): &quot;, tf.size(rank_4_tensor).numpy())
</pre></div>
</div>
</div>
</div>
<p>Axes of a tensor follow a global to local ordering. For example, in machine learning we often talk about batches. For a given batch, the dimension of the batch is ordered first, followed by the batch element’s spatial dimensions (height, width) and then the channels (referred to as features in the below diagram).</p>
<table>
<tr>
<th>Typical axis order</th>
</tr>
<tr>
    <td>
<img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/shape2.png?raw=1" alt="Keep track of what each axis is. A 4-axis tensor might be: Batch, Width, Height, Channels">
  </td>
</tr>
</table></section>
<section id="types-of-tensors-often-used">
<h3>Types of tensors often used<a class="headerlink" href="#types-of-tensors-often-used" title="Permalink to this heading">#</a></h3>
<p>Most tensors we encounter in computer vision contain floats and integers, but tensors can also represent other types, such as:</p>
<ul class="simple">
<li><p>complex numbers</p></li>
<li><p>strings</p></li>
</ul>
<p>TensorFlow requires a <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code> to be “rectangular,” which means that every element along an axis is the same size. There are exceptions to this (ragged and sparse tensors, but those are more rare).</p>
<p>We can calculate basic mathematical operations on tensors, such as addition, element-wise multiplication, and matrix multiplication.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>a = tf.constant([[1, 2],
                 [3, 4]])
b = tf.constant([[1, 1],
                 [1, 1]]) # Could have also said `tf.ones([2,2], dtype=tf.int32)`

print(tf.add(a, b), &quot;\n&quot;) # element-wise addition
print(tf.multiply(a, b), &quot;\n&quot;) # element-wise multiplication
print(tf.matmul(a, b), &quot;\n&quot;) # matrix multiplication
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>print(a + b, &quot;\n&quot;) # element-wise addition
print(a * b, &quot;\n&quot;) # element-wise multiplication
print(a @ b, &quot;\n&quot;) # matrix multiplication
</pre></div>
</div>
</div>
</div>
<p>Tensors are used in many types of operations (or “Ops”), such as common machine learning operations like <code class="docutils literal notranslate"><span class="pre">tf.math.argmax</span></code> and <code class="docutils literal notranslate"><span class="pre">tf.nn.softmax</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>c = tf.constant([[4.0, 5.0], [10.0, 1.0]])

# Find the largest value
print(tf.reduce_max(c))
# Find the index of the largest value
print(tf.math.argmax(c))
# Compute the softmax
print(tf.nn.softmax(c))
</pre></div>
</div>
</div>
</div>
<p>NumPy arrays can be created from tensors using either the <code class="docutils literal notranslate"><span class="pre">np.array</span></code> or <code class="docutils literal notranslate"><span class="pre">tensor.numpy</span></code> methods:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>rank_2_tensor.numpy()
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>np.array(rank_2_tensor)
</pre></div>
</div>
</div>
</div>
<p>Generally, where tensors are expected, TensorFlow functions additionally accept anything that can be converted to a <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> using <code class="docutils literal notranslate"><span class="pre">tf.convert_to_tensor</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>tf.convert_to_tensor([1,2,3]) # List
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>tf.reduce_max([1,2,3]) # List
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>tf.reduce_max(np.array([1,2,3])) # NumPy array
</pre></div>
</div>
</div>
</div>
</section>
<section id="variables">
<h3>Variables<a class="headerlink" href="#variables" title="Permalink to this heading">#</a></h3>
<p>As previously mentioned, normal <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code>s are immutable. However, some objects will change over time, like the trainable weights in a machine learning model. We want to store these values, so in order to do that, we need a tensor that can change. Enter the <code class="docutils literal notranslate"><span class="pre">tf.Variable</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>var = tf.Variable([0.0, 0.0, 0.0]) # example rank 1 variable
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>var.assign([1, 2, 3]) # change / re-assign the contents of the variable
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>var.assign_add([1, 1, 1]) # change the contents of the variable using an operation
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="indexing">
<h2>Indexing<a class="headerlink" href="#indexing" title="Permalink to this heading">#</a></h2>
<section id="single-axis-indexing">
<h3>Single-axis indexing<a class="headerlink" href="#single-axis-indexing" title="Permalink to this heading">#</a></h3>
<p>In TensorFlow, standard Python indexing rules apply. Indexing tensors looks similar to <a class="reference external" href="https://docs.python.org/3/tutorial/introduction.html#strings">indexing a list in Python</a>. The same applied for NumPy-style indexing.</p>
<ul class="simple">
<li><p>indexes begin at <code class="docutils literal notranslate"><span class="pre">0</span></code></p></li>
<li><p>negative indices count backwards from the end</p></li>
<li><p>colons, <code class="docutils literal notranslate"><span class="pre">:</span></code>, are used for slices: <code class="docutils literal notranslate"><span class="pre">start:stop:step</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])
print(rank_1_tensor.numpy())
</pre></div>
</div>
</div>
</div>
<p>When using a scalar to get an element in the tensor, the axis is removed.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>print(&quot;First:&quot;, rank_1_tensor[0].numpy())
print(&quot;Second:&quot;, rank_1_tensor[1].numpy())
print(&quot;Last:&quot;, rank_1_tensor[-1].numpy())
</pre></div>
</div>
</div>
</div>
<p>When a slice is indexed using <code class="docutils literal notranslate"><span class="pre">:</span></code> the axis is retained:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>print(&quot;Everything:&quot;, rank_1_tensor[:].numpy())
print(&quot;Before 4:&quot;, rank_1_tensor[:4].numpy())
print(&quot;From 4 to the end:&quot;, rank_1_tensor[4:].numpy())
print(&quot;From 2, before 7:&quot;, rank_1_tensor[2:7].numpy())
print(&quot;Every other item:&quot;, rank_1_tensor[::2].numpy())
print(&quot;Reversed:&quot;, rank_1_tensor[::-1].numpy())
</pre></div>
</div>
</div>
</div>
</section>
<section id="multi-axis-indexing">
<h3>Multi-axis indexing<a class="headerlink" href="#multi-axis-indexing" title="Permalink to this heading">#</a></h3>
<p>When working with higher ranks of tensors, we may have to use multiple indices.</p>
<p>To do this, we treat each axis independently with the exact same rules as in the single-axis case.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>print(rank_2_tensor.numpy())
</pre></div>
</div>
</div>
</div>
<p>If we pass an integer for each index for each axis, a scalar is returned.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># Pull out a single value from a 2-rank tensor
print(rank_2_tensor[1, 1].numpy())
</pre></div>
</div>
</div>
</div>
<p>We can combine integers and slices when indexing too. This can be useful if, for example, we want a subset of an image.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># Get row and column tensors
print(&quot;Second row:&quot;, rank_2_tensor[1, :].numpy())
print(&quot;Second column:&quot;, rank_2_tensor[:, 1].numpy())
print(&quot;Last row:&quot;, rank_2_tensor[-1, :].numpy())
print(&quot;First item in last column:&quot;, rank_2_tensor[0, -1].numpy())
print(&quot;Skip the first row:&quot;)
print(rank_2_tensor[1:, :].numpy(), &quot;\n&quot;)
</pre></div>
</div>
</div>
</div>
<p>An example for a tensor with 3 axes:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>print(rank_3_tensor[:, :, 4])
</pre></div>
</div>
</div>
</div>
<table>
<tr>
<th colspan=2>Selecting the last feature across all locations in each example in the batch </th>
</tr>
<tr>
    <td>
<img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/index1.png?raw=1" alt="A 3x2x5 tensor with all the values at the index-4 of the last axis selected.">
  </td>
      <td>
<img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/index2.png?raw=1" alt="The selected values packed into a 2-axis tensor.">
  </td>
</tr>
</table><p>More on how to apply indexing can be found in the <a class="reference external" href="https://tensorflow.org/guide/tensor_slicing">tensor slicing guide</a>.</p>
</section>
</section>
<section id="manipulating-tensor-shapes">
<h2>Manipulating tensor shapes<a class="headerlink" href="#manipulating-tensor-shapes" title="Permalink to this heading">#</a></h2>
<p>Sometimes, we need to reshape a tensor. For example, we flatten rank 2 tensors to rank 1 when computing things like confusion matrices.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># Shape returns a `TensorShape` object that shows the size along each axis
x = tf.constant([[1, 2, 3],
                [4, 5, 6],
                [7, 8, 9]])
print(x.shape)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># Flatten the rank 2 tensor to rank 1 (a vector)
x_flat = tf.reshape(x, [-1])
print(x_flat)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># Shape returns a `TensorShape` object that shows the size along each axis
x = tf.constant([[1], [2], [3]])
print(x.shape)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># You can convert this object into a Python list, too
print(x.shape.as_list())
</pre></div>
</div>
</div>
</div>
<p>A tensor can be manipulated into a new shape using the <code class="docutils literal notranslate"><span class="pre">tf.reshape</span></code> operation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># You can reshape a tensor to a new shape.
# Note that you&#39;re passing in a list
reshaped = tf.reshape(x, [1, 3])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>print(x.shape)
print(reshaped.shape)
</pre></div>
</div>
</div>
</div>
<p>The original tensor and the newly created one are both held in memory (remember tensors are immutable). TensorFlow abides by C-style “row-major” memory ordering, which means that an increment on the rightmost index corresponds to a single step in memory.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>print(rank_3_tensor)
</pre></div>
</div>
</div>
</div>
<p>In fact, flattening a tensor shows the order in which it is held in memory.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># A `-1` passed in the `shape` argument says &quot;Whatever fits&quot;.
print(tf.reshape(rank_3_tensor, [-1]))
</pre></div>
</div>
</div>
</div>
<p>Generally we use <code class="docutils literal notranslate"><span class="pre">tf.reshape</span></code> to combine or split adjacent axes (or add/remove <code class="docutils literal notranslate"><span class="pre">1</span></code>s, similar to <code class="docutils literal notranslate"><span class="pre">np.squeeze</span></code>).</p>
<p>Taking the below 3x2x5 tensor, we can reshape to (3x2)x5 or 3x(2x5) for example.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>print(tf.reshape(rank_3_tensor, [3*2, 5]), &quot;\n&quot;)
print(tf.reshape(rank_3_tensor, [3, -1]))
</pre></div>
</div>
</div>
</div>
<table>
<th colspan=3>
Some good reshapes.
</th>
<tr>
  <td>
<img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/reshape-before.png?raw=1" alt="A 3x2x5 tensor">
  </td>
  <td>
  <img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/reshape-good1.png?raw=1" alt="The same data reshaped to (3x2)x5">
  </td>
  <td>
<img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/reshape-good2.png?raw=1" alt="The same data reshaped to 3x(2x5)">
  </td>
</tr>
</table>
<p>Notes:</p>
<ul class="simple">
<li><p>We can reshape a tensor to a new shape so long as it entails the same total number of elements (size).</p></li>
<li><p>Shifting the order of axes is done with <code class="docutils literal notranslate"><span class="pre">tf.transpose</span></code> instead of <code class="docutils literal notranslate"><span class="pre">tf.reshape</span></code>.</p></li>
<li><p>You may run across not-fully-specified shapes. Either the shape contains a <code class="docutils literal notranslate"><span class="pre">None</span></code> (an axis-length is unknown) or the whole shape is <code class="docutils literal notranslate"><span class="pre">None</span></code> (the rank of the tensor is unknown). This is often useful for machine learning when the images in a batch may have non-uniform width and height dimensions.</p></li>
</ul>
</section>
<section id="tensor-dtypes">
<h2>Tensor <code class="docutils literal notranslate"><span class="pre">DTypes</span></code><a class="headerlink" href="#tensor-dtypes" title="Permalink to this heading">#</a></h2>
<p>We can find a <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code>’s data type by inspecting the <code class="docutils literal notranslate"><span class="pre">Tensor.dtype</span></code> property.</p>
<p>Datatypes can be optionally specified when creating a <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code> from a Python object. If left unspecified, TensorFlow inuits and assigns a datatype that can reasonably represent the data. By default, TensorFlow translates Python integers as <code class="docutils literal notranslate"><span class="pre">tf.int32</span></code> and Python floating point numbers as <code class="docutils literal notranslate"><span class="pre">tf.float32</span></code>.</p>
<p>Tensors can be cast to other types.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>the_f64_tensor = tf.constant([2.2, 3.3, 4.4], dtype=tf.float64)
the_f16_tensor = tf.cast(the_f64_tensor, dtype=tf.float16)
# Now, cast to an uint8 and lose the decimal precision
the_u8_tensor = tf.cast(the_f16_tensor, dtype=tf.uint8)
print(the_u8_tensor)
</pre></div>
</div>
</div>
</div>
</section>
<section id="broadcasting">
<h2>Broadcasting<a class="headerlink" href="#broadcasting" title="Permalink to this heading">#</a></h2>
<p>Broadcasting in TensorFlow is based on the <a class="reference external" href="https://numpy.org/doc/stable/user/basics.broadcasting.html">equivalent method in NumPy</a>.  The premise is that sometimes we need to stretch smaller tensors automatically to fit the size of larger tensors to run combined operations on them.</p>
<p>A simple example is multiplying or adding a tensor to a scalar. The scalar in this case is broadcast to the same shape as the tensor.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>x = tf.constant([1, 2, 3])

y = tf.constant(2)
z = tf.constant([2, 2, 2])
# All of these are the same computation
print(tf.multiply(x, 2))
print(x * y)
print(x * z)
</pre></div>
</div>
</div>
</div>
<p>Furthermore, tensors with an axis of length 1 can be stretched to match the axis length of another tensor during a combined operation.</p>
<p>As an example, a 3x1 matrix can be element-wise multiplied by a 1x4 matrix to result in a 3x4 matrix. The notation of the axis with length 1 is optional. In other words, the real shape of y is <code class="docutils literal notranslate"><span class="pre">[4]</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># These are the same computations
x = tf.reshape(x,[3,1])
y = tf.range(1, 5)
print(x, &quot;\n&quot;)
print(y, &quot;\n&quot;)
print(tf.multiply(x, y))
</pre></div>
</div>
</div>
</div>
<table>
<tr>
  <th>A broadcasted add: a <code>[3, 1]</code> times a <code>[1, 4]</code> gives a <code>[3,4]</code> </th>
</tr>
<tr>
  <td>
<img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/broadcasting.png?raw=1" alt="Adding a 3x1 matrix to a 4x1 matrix results in a 3x4 matrix">
  </td>
</tr>
</table>
<p>The same operation without broadcasting looks like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>x_stretch = tf.constant([[1, 1, 1, 1],
                         [2, 2, 2, 2],
                         [3, 3, 3, 3]])

y_stretch = tf.constant([[1, 2, 3, 4],
                         [1, 2, 3, 4],
                         [1, 2, 3, 4]])

print(x_stretch * y_stretch)  # Again, operator overloading
</pre></div>
</div>
</div>
</div>
<p>Broadcasting is usually both time and space efficient, as it never creates the expanded tensors in memory.</p>
<p>The broadcasting operation can be observed with <code class="docutils literal notranslate"><span class="pre">tf.broadcast_to</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>print(tf.broadcast_to(tf.constant([1, 2, 3]), [3, 3]))
</pre></div>
</div>
</div>
</div>
<p>More on broadcasting can be found in <a class="reference external" href="https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html">this section</a> of Jake VanderPlas’s book <em>Python Data Science Handbook</em>.</p>
</section>
<section id="tf-convert-to-tensor">
<h2>tf.convert_to_tensor<a class="headerlink" href="#tf-convert-to-tensor" title="Permalink to this heading">#</a></h2>
<p>As a reminder, most TensorFlow operations that expect arguments of class <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code>, such as <code class="docutils literal notranslate"><span class="pre">tf.matmul</span></code> and <code class="docutils literal notranslate"><span class="pre">tf.reshape</span></code>, will also accept Python objects shaped like tensors.</p>
<p>Under the hood, most TensorFlow ops apply <code class="docutils literal notranslate"><span class="pre">convert_to_tensor</span></code> to non-tensor arguments, such as NumPy’s <code class="docutils literal notranslate"><span class="pre">ndarray</span></code>, <code class="docutils literal notranslate"><span class="pre">TensorShape</span></code>, Python lists, and <code class="docutils literal notranslate"><span class="pre">tf.Variable</span></code>, all of which will convert automatically.</p>
<p>See the conversion registry <code class="docutils literal notranslate"><span class="pre">tf.register_tensor_conversion_function</span></code> to know whether a data type will automatically convert.</p>
</section>
<section id="string-tensors">
<h2>String tensors<a class="headerlink" href="#string-tensors" title="Permalink to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">tf.string</span></code> is a <code class="docutils literal notranslate"><span class="pre">dtype</span></code> that represents data as strings (variable-length byte arrays) in tensors.</p>
<p>However, string tensors are atomic meaning that they cannot be indexed the way Python strings can. See <code class="docutils literal notranslate"><span class="pre">tf.strings</span></code> for ways to manipulate them.</p>
<p>An example of a scalar string tensor:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># Tensors can be strings, too here is a scalar string.
scalar_string_tensor = tf.constant(&quot;Lima Peru&quot;)
print(scalar_string_tensor)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># If you have three string tensors of different lengths, this is OK.
tensor_of_strings = tf.constant([&quot;Lima Peru&quot;,
                                 &quot;NASA SERVIR&quot;,
                                 &quot;Development Seed&quot;])
# Note that the shape is (3,). The string length is not included.
print(tensor_of_strings)
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">b</span></code> prefix in the above printout indicates that the <code class="docutils literal notranslate"><span class="pre">tf.string</span></code> dtype is a byte-string, not a unicode string. For more on how to use unicode text in TensorFlow see the <a class="reference external" href="https://www.tensorflow.org/tutorials/load_data/unicode">Unicode Tutorial</a>.</p>
<p>Also worth noting, unicode characters in TensorFlow are utf-8 encoded.</p>
<p><code class="docutils literal notranslate"><span class="pre">tf.strings</span></code> contains some basic string operations, including <code class="docutils literal notranslate"><span class="pre">tf.strings.split</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># You can use split to split a string into a set of tensors
print(tf.strings.split(scalar_string_tensor, sep=&quot; &quot;))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># ...but it turns into a what is known as a `RaggedTensor` if you split up a tensor of strings,
# as each string might be split into a different number of parts.
print(tf.strings.split(tensor_of_strings))
</pre></div>
</div>
</div>
</div>
<p>And we also have <code class="docutils literal notranslate"><span class="pre">tf.string.to_number</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>text = tf.constant(&quot;1 10 100&quot;)
print(tf.strings.to_number(tf.strings.split(text, &quot; &quot;)))
</pre></div>
</div>
</div>
</div>
<p>In TensorFlow, the <code class="docutils literal notranslate"><span class="pre">tf.string</span></code> dtype describes all raw bytes data. The <code class="docutils literal notranslate"><span class="pre">tf.io</span></code> module is used to convert data to and from bytes, as is done when decoding images and parsing text.</p>
</section>
<section id="sparse-tensors">
<h2>Sparse tensors<a class="headerlink" href="#sparse-tensors" title="Permalink to this heading">#</a></h2>
<p>Data can sometimes be sparse, as might be the case for a wide embedding space.  TensorFlow has a datat type called <code class="docutils literal notranslate"><span class="pre">tf.sparse.SparseTensor</span></code> and related operations to support sparse data and work efficiently with it.</p>
<table>
<tr>
  <th>A `tf.SparseTensor`, shape: <code>[3, 4]</code></th>
</tr>
<tr>
  <td>
<img src="https://github.com/tensorflow/docs/blob/master/site/en/guide/images/tensor/sparse.png?raw=1" alt="An 3x4 grid, with values in only two of the cells.">
  </td>
</tr>
</table><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># Sparse tensors store values by index in a memory-efficient manner
sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],
                                       values=[1, 2],
                                       dense_shape=[3, 4])
print(sparse_tensor, &quot;\n&quot;)

# You can convert sparse tensors to dense
print(tf.sparse.to_dense(sparse_tensor))
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="functions">
<h1>Functions<a class="headerlink" href="#functions" title="Permalink to this heading">#</a></h1>
<p>In TensorFlow 2, <span class="xref myst">eager execution</span> mode is on by default. This mode enables intuitive use, rapid experimentation and flexibility. However, this mode faces limits with performance and deployability.</p>
<p><code class="docutils literal notranslate"><span class="pre">tf.function</span></code> is used to make graphs out of programs. The critical case for it is when we need to build Python-independent dataflow graphs from Python code, with goal of creating performant and portable models. In fact, compiling in <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> is required to use the <code class="docutils literal notranslate"><span class="pre">SavedModel</span></code> class.</p>
<p>We will discuss some of the main uses for <code class="docutils literal notranslate"><span class="pre">tf.function</span></code>.</p>
<p>Before that, it’s worth knowing how and when <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> is recommended:</p>
<ul class="simple">
<li><p>Debugging is best done in eager mode, then functions from that should be decorated with <code class="docutils literal notranslate"><span class="pre">&#64;tf.function</span></code>.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> to avoid on Python side effects like object mutation or list appends.</p></li>
</ul>
<p>Some notes on Keras w.r.t. <code class="docutils literal notranslate"><span class="pre">tf.function</span></code>:</p>
<p>For machine learning, if you don’t need low-level control of your model training, use the Keras API.</p>
<ul class="simple">
<li><p>The Keras API accepts NumPy arrays, Python generators and, tf.data.Datasets.</p></li>
<li><p>It abstracts away the implementation of regularization, activation, and loss calculation, all of which are easily included.</p></li>
<li><p>The Keras API supports <code class="docutils literal notranslate"><span class="pre">tf.distribute</span></code> to increase the compute efficiency regardless of the hardware configuration.</p></li>
<li><p>It supports arbitrary/custom losses and metrics.</p></li>
<li><p>The Keras API supports callbacks such as <code class="docutils literal notranslate"><span class="pre">tf.keras.callbacks.TensorBoard</span></code> for enhanced logging and visualization, and also custom callbacks.</p></li>
<li><p>It is easy to use and performant, as it automatically uses TensorFlow graphs under the hood.</p></li>
</ul>
<section id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Permalink to this heading">#</a></h2>
<p>A <code class="docutils literal notranslate"><span class="pre">Function</span></code> in TensorFlow, (which can be created by adding the <code class="docutils literal notranslate"><span class="pre">&#64;tf.function</span></code> decorator) behaves like a core TensorFlow operation. It can be executed eagerly.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>@tf.function  # The decorator converts `add` into a `Function`.
def add(a, b):
  return a + b

add(tf.ones([2, 2]), tf.ones([2, 2]))  #  [[2., 2.], [2., 2.]]
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">Function</span></code>s can be used inside other <code class="docutils literal notranslate"><span class="pre">Function</span></code>s.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>@tf.function
def dense_layer(x, w, b):
  return add(tf.matmul(x, w), b)

dense_layer(tf.ones([3, 2]), tf.ones([2, 2]), tf.ones([2]))
</pre></div>
</div>
</div>
</div>
<p>In some cases, <code class="docutils literal notranslate"><span class="pre">Function</span></code>s are faster than their eager code equivalent. This is especially so for graphs with lots of small ops. However, on the flip side graphs with few expensive ops (like convolutions) may not benefit from much speedup.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import timeit
conv_layer = tf.keras.layers.Conv2D(100, 3)

@tf.function
def conv_fn(image):
  return conv_layer(image)

image = tf.zeros([1, 200, 200, 100])
# Warm up
conv_layer(image); conv_fn(image)
print(&quot;Eager conv:&quot;, timeit.timeit(lambda: conv_layer(image), number=10))
print(&quot;Function conv:&quot;, timeit.timeit(lambda: conv_fn(image), number=10))
print(&quot;Note how there&#39;s not much difference in performance for convolutions&quot;)
</pre></div>
</div>
</div>
</div>
<section id="use-unknown-dimensions-for-flexibility">
<h3>Use unknown dimensions for flexibility<a class="headerlink" href="#use-unknown-dimensions-for-flexibility" title="Permalink to this heading">#</a></h3>
<p>TensorFlow matches tensorson the basis of their shape. We can use a <code class="docutils literal notranslate"><span class="pre">None</span></code> dimension as a wildcard to allow <code class="docutils literal notranslate"><span class="pre">Function</span></code>s to run on variably-sized input. Variably-sized input is frequent when dealing with sequences of different length, or images of different spatial dimensions (sizes) across batches.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.int32),))
def g(x):
  print(x)
  return x

print(g(tf.constant([1, 2, 3])))
print(g(tf.constant([1, 2, 3, 4, 5])))
</pre></div>
</div>
</div>
</div>
</section>
<section id="using-iterators-and-generators">
<h3>Using iterators and generators<a class="headerlink" href="#using-iterators-and-generators" title="Permalink to this heading">#</a></h3>
<p>TensorFlow has a <code class="docutils literal notranslate"><span class="pre">tf.data.Iterator</span></code> for iteration. The <a class="reference external" href="https://www.tensorflow.org/guide/data"><code class="docutils literal notranslate"><span class="pre">tf.data</span></code></a> API helps implement generator patterns. TensorFlow’s iterators and generators help avoid Python side effects which can surface outside of eager mode.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>@tf.function
def buggy_consume_next(iterator):
  tf.print(&quot;Value:&quot;, next(iterator))

iterator = iter([1, 2, 3])
buggy_consume_next(iterator)
# This reuses the first value from the iterator, rather than consuming the next value.
buggy_consume_next(iterator)
buggy_consume_next(iterator)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>@tf.function
def good_consume_next(iterator):
  # This is ok, iterator is a tf.data.Iterator
  tf.print(&quot;Value:&quot;, next(iterator))

ds = tf.data.Dataset.from_tensor_slices([1, 2, 3])
iterator = iter(ds)
good_consume_next(iterator)
good_consume_next(iterator)
good_consume_next(iterator)
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="data">
<h1>Data<a class="headerlink" href="#data" title="Permalink to this heading">#</a></h1>
<p>The <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset">API</a> represents methods to create tensor-formatted datasets out of many different types of data.</p>
<p>Usage of the API follows the below pattern:</p>
<ul class="simple">
<li><p>Create a dataset from your input data.</p></li>
<li><p>Iterate over the dataset, applying any dataset transformations to the data.</p></li>
</ul>
<p>Note that iteration occurs through streaming, so it dones’t matter if a full dataset can’t fit into memory.</p>
<p>The simplest example of creating a dataset is from a python list:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])
for element in dataset:
  print(element)
</pre></div>
</div>
</div>
</div>
<p>Transformations:
With a dataset, you can use transformations to prepare the data. In machine learning, sometimes we want to augment our data with image flips and rotations for example. Those could be done in the pipeline too.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])
dataset = dataset.map(lambda x: x*2)
list(dataset.as_numpy_iterator())
</pre></div>
</div>
</div>
</div>
<p>Common Terms:</p>
<ul class="simple">
<li><p><strong>Element</strong>: A single result from calling next() on a dataset iterator. Elements are sometimes nested structures containing multiple components.</p></li>
<li><p><strong>Component</strong>: The single part in a nested structure of an element.</p></li>
</ul>
<p>Supported types:</p>
<p>As nested structures, elements can contain tuples, named tuples, and dictionaries. This is different behavior than that of Python lists. Instead, Python lists require conversion to tensors and then may be treated as components. Element components can express as any type represented in <code class="docutils literal notranslate"><span class="pre">tf.TypeSpec</span></code>, which includes <code class="docutils literal notranslate"><span class="pre">tf.Tensor</span></code>, <code class="docutils literal notranslate"><span class="pre">tf.data.Datase</span></code>t, <code class="docutils literal notranslate"><span class="pre">tf.sparse.SparseTensor</span></code>, and <code class="docutils literal notranslate"><span class="pre">tf.TensorArray</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>a = 1 # Integer element
b = 2.0 # Float element
c = (1, 2) # Tuple element with 2 components
d = {&quot;a&quot;: (2, 2), &quot;b&quot;: 3} # Dict element with 3 components
Point = collections.namedtuple(&quot;Point&quot;, [&quot;x&quot;, &quot;y&quot;])
e = Point(1, 2) # Named tuple
f = tf.data.Dataset.range(10) # Dataset element
</pre></div>
</div>
</div>
</div>
<p>We can directly read images and labels from <code class="docutils literal notranslate"><span class="pre">np.array</span></code> format into <code class="docutils literal notranslate"><span class="pre">tf.data.dataset</span></code>. In the below example, we are creating synthetic 3 channel images and single channel labels with uniform spatial dimensions and subsequently reading them into a dataset using the <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset.from_tensor_slices</span></code> method. This works if you can fit the NumPy arrays in memory for the images and labels, but if not you’ll need to use a data pipe (example in later tutorial).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>image1, image2, image3 = np.zeros((3, 10,10)), np.zeros((3, 10,10)), np.zeros((3, 10,10))
label1, label2, label3 = np.ones((10,10)), np.ones((10,10)), np.ones((10,10))

images = [image1, image2, image3]
labels = [label1, label2, label3]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>dataset = tf.data.Dataset.from_tensor_slices((images, labels))
dataset
</pre></div>
</div>
</div>
</div>
<section id="data-pipelines">
<h2>Data pipelines<a class="headerlink" href="#data-pipelines" title="Permalink to this heading">#</a></h2>
<p>We can use the <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> API iterators and generators to construct data pipelines. A data pipeline is used to map a set of processing steps on a large amount of data. With such pipelines, we can stream data iteratively to the same reusable code for processing and have it contribute to the same dataset (e.g. training or validation). As an example, an image data pipeline might involve reading image files from a file system, applying random perturbations or other augmentations to each image, and then randomly shuffling and appending images to a batch for training. In essence, data pipelines built with the <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> API enable large amounts of data to be read, with support for different data formats, and complex transformations. We will explore a data pipeline in a subsequent lesson, but if you’re curious about data pipelines, you can read more via this <a class="reference external" href="https://www.tensorflow.org/guide/data">guide</a>.</p>
<figure class="align-default" id="datapipe-fig">
<a class="reference internal image-reference" href="https://storage.googleapis.com/jalammar-ml/tf.data/images/tf.data-simple-pipeline.png"><img alt="https://storage.googleapis.com/jalammar-ml/tf.data/images/tf.data-simple-pipeline.png" src="https://storage.googleapis.com/jalammar-ml/tf.data/images/tf.data-simple-pipeline.png" style="width: 650px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 18 </span><span class="caption-text">Figure from <a class="reference external" href="https://www.kaggle.com/code/jalammar/intro-to-data-input-pipelines-with-tf-data">Intro to Data Input Pipelines with tf.data
</a></span><a class="headerlink" href="#datapipe-fig" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>This discussion on datasets is different than the <a class="reference external" href="https://www.tensorflow.org/datasets">TensorFlow Datasets collection</a> which hosts prepared datasets for TensorFlow models and analysis. We will explore use of the TensorFlow Datasets collection also in a subsequent lesson.</p>
<p>This notebook was adapted from <a class="reference external" href="https://www.tensorflow.org/guide/tensor">Introduction to Tensors</a>, <a class="reference external" href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/function.ipynb#scrollTo=HQrG5_kOiKl_">TensorFlow Functions</a>, and <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset">tf.data.Dataset API</a>.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./docs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="Lesson2b_Intro_to_TF2_Keras_TFDS_RadiantEarth.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">TensorFlow 2 and Keras quickstart for geospatial computer vision</p>
      </div>
    </a>
    <a class="right-next"
       href="Lesson4b_Integrations_with_Google_Cloud_Platform.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">What are cloud providers? Why might I need them for ML and Earth observation data?</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Introduction to Tensors, TensorFlow Functions and TensorFlow Datasets</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basics-of-tensors">Basics of tensors</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#significance-of-tensor-shapes">Significance of Tensor shapes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpreting-tensor-shapes">Interpreting tensor shapes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-tensors-often-used">Types of tensors often used</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#variables">Variables</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#indexing">Indexing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#single-axis-indexing">Single-axis indexing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-axis-indexing">Multi-axis indexing</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#manipulating-tensor-shapes">Manipulating tensor shapes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tensor-dtypes">Tensor <code class="docutils literal notranslate"><span class="pre">DTypes</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#broadcasting">Broadcasting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tf-convert-to-tensor">tf.convert_to_tensor</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#string-tensors">String tensors</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sparse-tensors">Sparse tensors</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#functions">Functions</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#usage">Usage</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-unknown-dimensions-for-flexibility">Use unknown dimensions for flexibility</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-iterators-and-generators">Using iterators and generators</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#data">Data</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-pipelines">Data pipelines</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Development Seed
</p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>