{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl_5Jv9Xr10t"
      },
      "source": [
        "# TensorFlow advanced applications with deep learning object detection, regression, time-series analysis, hyper-parameter tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx-HvbTNr10w"
      },
      "source": [
        "## Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aCvX-Urr10x"
      },
      "source": [
        "- Understand the limits of deep learning models built to work with 3D imagery and variants that have been developed for 4D time series\n",
        "- Understand theory, use cases, and architecture options for time series modeling and change detection\n",
        "\n",
        "\n",
        "- Understand difference between semantic segmentation and object detection, labeling and modeling challenges with each approach\n",
        "- Cover R-CNN family, Yolo object detection families of architectures.\n",
        "- Understand theory, use cases, and architecture options for regression\n",
        "- Understand when to hyperparameter tune, and the pros/cons of different approaches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Semantic Segmentation with U-Net\n",
        "\n",
        "In Lesson 1a Introduction to ML Neural Networks and Deep Learning, we introduced the U-Net architecture, a popular architecture in remote sensing. U-Net has been onw of the most popular architectures for segmentation fo remote sensing images because:\n",
        "\n",
        "1. Since U-Net is fully convolutional, it requires fewer parameters to train than models with multiple heads (R-CNNs) or models with many fully connected layers.\n",
        "2. U-Net's skip connections learns powerful features across many spatial scales that preserve high resolution features \n",
        "3. the U-Net architecture can handle very high resolution images without saturating GPU memory, unlike other frameworks that learn many features per each section of an image.\n",
        "\n",
        "U-net is therefore one of the most popular architectures for segmentation in very high resolution imagery (and low resolution imagery as well). At Development Seed, we've used CNN-based U-Net architectures for segmentation of supraglacial lakes https://developmentseed.org/blog/2022-12-13-segmenting-supraglacial-lakes\n",
        "\n",
        "The traditional U-net architecture has been adapted and improved to work with high resolution 2D and 3D imagery. Of these SSCA-Net has been a popular option which uses self and channel attention.\n",
        "\n",
        ":::{figure-md} SCCANetFig\n",
        "<img src=\"./images/scca.jpg\" width=\"450px\">\n",
        "\n",
        "[SCCA Image](./images/scca.jpg) from \"SSCA-Net: Simultaneous Self- and Channel-Attention Neural Network for Multiscale Structure-Preserving Vessel Segmentation\"\n",
        ":::\n",
        "\n",
        "In the above figure, the SCCANet reflects the structure of a U-Net with some modifications:\n",
        "1. The typical initial residual blocks in the encoder have been replaced by an RFU block, which is simply a 3x3 convolution followed by batch normalization and RELU.\n",
        "2. They use a squeeze and excitation pyramid pooling (SEPP) module at the end of the encoder, which makes use of atrous convolutions and a spatial pyramid to account for multiscale features.\n",
        "3. The decoder includes SCA modules that use self and channel attention to efficiently model long range dependencies in feature maps that are learned from previous convolution operations.\n",
        "\n",
        "\n",
        "However, when it comes to modeling with image time series, a traditional 3D U-Net won't work, since it's structure does not account for the time dimension. Extensions of U-Net and other fully convolutional networks have been developed to address 4D data cubes (time, bands, height, width). These approaches either use CNNs to model the relationships along a time sequence or variants of attention.\n",
        "\n",
        "Recent approaches in this vein include:\n",
        "\n",
        "1. [ScaleMAE - A Scale-Aware Masked Autoencoder for Multiscale Geospatial Representation Learning](https://arxiv.org/pdf/2212.14532.pdf)\n",
        "2. [SatMAE - Pre-training Transformers for Temporal and Multi-Spectral Satellite Imagery](https://arxiv.org/pdf/2207.08051.pdf)\n",
        "\n",
        "Of these, ScaleMAE is more recent and shows favorable performance relative to SatMAE.\n",
        "\n",
        ":::{figure-md} ScaleMAEFig\n",
        "<img src=\"[./images/scca.jpg](https://ai-climate.berkeley.edu/scale-mae-website/static/images/scale-teaser.png)\" width=\"450px\">\n",
        "\n",
        "[ScaleMAE Image]([./images/scca.jpg](https://ai-climate.berkeley.edu/scale-mae-website/static/images/scale-teaser.png)) from \"A Scale-Aware Masked Autoencoder for Multiscale Geospatial Representation Learning\"\n",
        ":::\n",
        "\n",
        "Scale-MAE has some important constraints:\n",
        "* the resolution of the sensor inputs must match.\n",
        "* GPU memory use is large relative to traditional MAE\n",
        "* It takes a really long time to train, relative to networks for 3D (this is a constraint for most networks that work with the space, time, and band dimension)\n",
        "* \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Object Detection and Instance Segmentation: Counting and mapping extent of instances\n",
        "\n",
        "\n",
        "* Yolo-V5 for wildlife detection, object detection\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Mask R-CNN for object detection and instance segmentation.\n",
        "1. Useful when your mapping targets are objects, meaning they have relatively simple boundaries, are not extremely disjoint, and occur within a well defined range of spatial scales and aspect ratios\n",
        "\n",
        "https://meetingorganizer.copernicus.org/EGU23/EGU23-16932.html\n",
        "https://docs.google.com/presentation/d/18wM5h4qxR3wev3Ix9HS0K3Z3E8Cjr2z2KoFXgrVCeF4/edit#slide=id.g23992ac5da2_4_25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Time series and change detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "tinyCD - change detection of fires with mixingmaskattention: https://github.com/developmentseed/chabud2023/blob/main/chabud/tinycd_model.py\n",
        "\n",
        "Presto - https://arxiv.org/pdf/2304.14065.pdf\n",
        "\n",
        "Operates on pixel time series of multi sensors, multi channel\n",
        "Channel group embedding, positional, embedding for lagoon, and month embedding\n",
        "Somewhat marginal but clear improvement over other approach (also time series approach)\n",
        "Geographic representation across hemispheres and ecoregion\n",
        "Used dynamic world as an input and to stratify\n",
        "Presto can be used as feature extractor (for random forest and regression) or fine-tuning the encoder and linear transformation\n",
        "Main comparison is to Task Informed Meta Learning\n",
        "Presto is fully self supervised, computationally more efficient than image based approaches\n",
        "Also beats SatMAE\n",
        "Also tested fully supervised presto to measure effect of arch vs the self supervision training regime\n",
        "Didnâ€™t really understand all presto tables, especially table 6\n",
        "Self supervised presto beats fully supervised presto for particular tasks\n",
        "\n",
        "Spatio-temporal transformer STT\n",
        "\n",
        "ConvLSTM: Effective for time series data in computer vision. Knowledge Distillation: Teacher-student networks where the student (smaller) network tries to imitate the teacher (larger) network. SCCANet (Spatial and Spectral Channel Attention Network): An evolved form of U-Net with attention mechanisms. Stacked AutoEncoder (SAM?): Focuses on lossless compression. Comparison with PCA and deep autoencoders. Introduction of Variational autoencoders. RaVAEn: Unsupervised learning for change detection. Image Retrieval: Using vector databases for similarity computations. Image Captioning: [Insert: Brief Explanation and Examples]\n",
        "\n",
        "Firecube: A daily data cube for the modeling and analysis of wildfires in Greece. Dataset is on zenodo\n",
        "\n",
        "Model types Pixel-wise = RF, XGBOOST Temporal pixel-wise: LSTM Spatiotemporal: ConvLSTM\n",
        "\n",
        "Showed convlstm does best, better than xgboost!\n",
        "\n",
        "\n",
        "M2-CDNET "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Lesson1a_Intro_ML_NN_DL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
