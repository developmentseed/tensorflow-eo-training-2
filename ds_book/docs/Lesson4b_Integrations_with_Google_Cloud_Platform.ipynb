{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are cloud providers? Why might I need them for ML and Earth observation data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three big cloud providers, Amazon Web Services, Microsoft Azure, and Google Cloud Platform, each provide three general services that can be essential when developing machine learning models and services on top of geospatial imagery:\n",
    "\n",
    "1. data warehouses containing many popular satellite, climate, weather, and other geospatial data archives\n",
    "1. the ability to rent computers with GPUs (graphical processing units), which can train machine learning models 10x-1000x faster than CPUs\n",
    "1. the ability to rent higher level computational services. \n",
    "  * Example 1: AWS Batch can perform batch processing (spinning up many machines to process lots of data). \n",
    "  * Example 2: Google Cloud Functions allow you to run code without managing servers (their lifecycle, starting them up and shutting them off, or the machine type). This paradigm of computing is called \"Serverless\", and allows you to execute code that scales by demand, in an event-driven way. Typically, this is pay-per-use.\n",
    "\n",
    "We typically need GPUs to train machine learning models. Because they are computationally intensive, we rely on GPUs to run training experiments in a reasonable amount of time (minutes instead of hours, or hours instead of days). \n",
    "\n",
    "Because IO (Input/Output) operations can take up a lot of time when training models or running model inference, it helps to run the compute next to the data. this means using cloud data storage directly rather than downloading files to another machine.\n",
    "\n",
    "Finally, if we want to build complex, event-driven services that use machine learning, cloud-based services are typically the easiest, most reproducible, most fault-tolerant, and most scalable way to build these services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Google Cloud Platform? How is it different from Google Colab?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google Cloud Platform (GCP) is a suite of cloud services including computing, data storage, data analytics and more. For a machine learning engineer looking to develop ML models on large geospatial datasets and integrate those models into applications for monitoring and detection, the following GCP services would be particularly useful:\n",
    "\n",
    "1. Compute Engine: Infrastructure as a Service (IaaS) providing VMs. This is suitable for running geospatial data processing or analysis tasks that require significant compute resources. It has the capability to provision machine types with varying amounts of GPU and CPU computing power as well as RAM and disk space.\n",
    "\n",
    "1. Cloud Storage: Object storage for keeping data, such as geospatial datasets, model checkpoints, and training data. It supports different storage classes (like multi-regional, regional, nearline, coldline) to optimize cost. The main receptacle for storing data in Cloud Storage is called a \"bucket\".\n",
    "\n",
    "1. Cloud Functions: Serverless compute service to run single-purpose code in response to events. This can be useful for smaller, event-driven tasks, like running a machine learning model on a satellite image whenever it is placed in a Google Cloud Storage bucket.\n",
    "\n",
    "1. IAM & Security: Ensures that your data and services are secure. Given the sensitivity of some geospatial data, understanding and implementing correct access controls is crucial.\n",
    "\n",
    "In addition, the following services may be useful alternatives setting up Cloud Functions or Compute Engine VMs directly. These may have added costs, harder to inspect costs, and may be less customizable for a particular application:\n",
    "\n",
    "1. Kubernetes Engine (GKE): Managed Kubernetes service for deploying, managing, and scaling containerized applications. This can be useful for deploying machine learning models as microservices.\n",
    "\n",
    "1. AI Platform Training: This service provides a managed service for training ML models at scale. It supports multiple ML frameworks such as TensorFlow, scikit-learn, and XGBoost. It also provides GPU and TPU support to accelerate training.\n",
    "\n",
    "1. AI Platform Prediction: Allows for deployment of trained machine learning models for making online predictions. It can expose your trained model as a RESTful API, which can be consumed by other applications.\n",
    "\n",
    "We have a preexisting Google Cloud project for the ACCA team. We'll use this to demo deploying a Machine Learning workstation with Terraform, which will let us start a Jupyter Notebook on a Compute Engine instance type of our choice, with as many GPUs, RAM, and disk space as we want that is supported by the instance type selection. These can be payed for with your preferred payment method or cloud credits if you have access to cloud credits via a partnership with a Google Affiliated program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying an ML Workstation with Terraform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCloud Terminal CLI Setup Instructions\n",
    "\n",
    "1. Install Google Cloud SDK: If you haven't installed the Google Cloud SDK on your machine, you can download and install it from the official Google Cloud website: https://cloud.google.com/sdk/docs/install. Then, accept the arguments with \"Y\" that append the CLI commands to your terminal configuration file, like your `~/.bashrc` or `~/.zshrc` file\n",
    "\n",
    "2. Initialize gcloud: After installing the SDK, open your terminal (command prompt) and run the following command to initialize gcloud:\n",
    "\n",
    "    ```\n",
    "    gcloud init\n",
    "    ```\n",
    "\n",
    "3. Login with your Google Account: The above command will prompt you to log in to your Google Account in your web browser. Click on the provided link, sign in with your Google Account, and authorize the SDK to access your Google Cloud resources.\n",
    "\n",
    "4. Select a project: If you have multiple projects associated with your Google Account, you'll be asked to choose the project you want to use. The list of projects will be displayed in the terminal, and you can select the appropriate project by typing the corresponding number.\n",
    "\n",
    "5. Set default configuration (optional): After selecting the project, you can choose to set it as the default configuration by typing \"Y\" when prompted. This will make it the default project for future gcloud commands.\n",
    "\n",
    "6. Configuration completion: Once the configuration is complete, you'll receive a message confirming that you are now authenticated and set up to use the selected Google Cloud project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terraform Setup Instructions\n",
    "\n",
    "1. Install terraform following these instructions: https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli You can skip the Quickstart tutorial\n",
    "1. Navigate to the gcpvm/ folder in this repository: TODO\n",
    "1. Run `terraform init` to initialize terraform and download the correct versions of libraries used to create the Google Cloud resources.\n",
    "1. Run `gcloud auth application-default login` to authenticate terraform to use the gcloud CLI to provision resources.\n",
    "2. For new projects, you may need to enable Compute Engine by visiting https://console.developers.google.com/apis/api/compute.googleapis.com/overview?project=161564225007 and changing settings.\n",
    "3. Run `terraform apply` to create the VM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying Cloud Functions for ML Inference with Pulumi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
